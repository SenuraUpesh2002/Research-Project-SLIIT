{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10ff6b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c30cd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "261b8e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a44b09cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "261ff0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b295057e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3eb99e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('records_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb89889c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'reading', 'reading_time', 'Fuel Volume (L)']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd9d8296",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Fuel Volume (L)'] = pd.to_numeric(df['Fuel Volume (L)'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49fad5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reading_time'] = pd.to_datetime(df['reading_time'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da343e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['reading_time', 'id']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1455ee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['volume_diff'] = df['Fuel Volume (L)'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "818a714e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prev_fuel_volume'] = df['Fuel Volume (L)'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "14a302c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rolling_mean'] = df['Fuel Volume (L)'].rolling(window=10, min_periods=5).mean()\n",
    "df['rolling_std'] = df['Fuel Volume (L)'].rolling(window=10, min_periods=5).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "09ba6de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra features to improve separability\n",
    "df[\"abs_volume_diff\"] = df[\"volume_diff\"].abs()\n",
    "# SOFT noise flag (not used in rule_label)\n",
    "df[\"soft_noise\"] = (\n",
    "    (df[\"abs_volume_diff\"] < 0.3) &\n",
    "    (df[\"prev_fuel_volume\"] > 0)\n",
    ").astype(int)\n",
    "df[\"zscore_volume\"] = (\n",
    "    df[\"Fuel Volume (L)\"] - df[\"rolling_mean\"]\n",
    ") / df[\"rolling_std\"]\n",
    "df[\"hour\"] = df[\"reading_time\"].dt.hour\n",
    "\n",
    "# Replace inf from zscore with NaN\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "2da44ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Business rules (2 L threshold)\n",
    "def rule_based_flag(row, threshold=2.0):\n",
    "    if pd.isna(row[\"Fuel Volume (L)\"]):\n",
    "        return 0\n",
    "\n",
    "    # impossible negative volume\n",
    "    if row[\"Fuel Volume (L)\"] < 0:\n",
    "        return 1\n",
    "\n",
    "    # large sudden drop (≥ 2 L)\n",
    "    if row[\"volume_diff\"] <= -threshold:\n",
    "        return 1\n",
    "\n",
    "    # large sudden refill (≥ 2 L)\n",
    "    if row[\"volume_diff\"] >= threshold:\n",
    "        return 1\n",
    "\n",
    "    return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a9c47ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New rule_label counts: [1222    6]\n"
     ]
    }
   ],
   "source": [
    "# 4. Business-rule label (rule_label) ---------------------------------------\n",
    "# Refill-from-zero records (same as before)\n",
    "refill_after_zero = (df[\"prev_fuel_volume\"] == 0) & (df[\"volume_diff\"] > 0)\n",
    "\n",
    "# Only big unexpected drops/raises are anomalies\n",
    "BIG_JUMP = 2.0  # tune this\n",
    "\n",
    "candidate_anomaly = (\n",
    "    (df[\"prev_fuel_volume\"] != 0) &\n",
    "    (df[\"volume_diff\"].abs() > BIG_JUMP)\n",
    ")\n",
    "\n",
    "df[\"rule_label\"] = 0\n",
    "df.loc[candidate_anomaly & (~refill_after_zero), \"rule_label\"] = 1\n",
    "\n",
    "print(\"New rule_label counts:\", np.bincount(df[\"rule_label\"].values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "34773c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 726\n",
      "Label distribution: [720   6]\n",
      "Train size: 508 Test size: 218\n",
      "Train labels: [505   3]\n",
      "Test labels : [215   3]\n"
     ]
    }
   ],
   "source": [
    "# 4. Clean dataset for modelling --------------------------------------------\n",
    "feature_cols = [\n",
    "    \"volume_diff\",\n",
    "    \"prev_fuel_volume\",\n",
    "    \"rolling_mean\",\n",
    "    \"rolling_std\",\n",
    "    \"abs_volume_diff\",\n",
    "    \"zscore_volume\",\n",
    "    \"hour\",\n",
    "    \"soft_noise\",\n",
    "]\n",
    "\n",
    "df_clean = df.dropna(subset=feature_cols + [\"rule_label\"]).copy()\n",
    "df_clean = df_clean.sort_values(\"reading_time\").reset_index(drop=True)\n",
    "\n",
    "X = df_clean[feature_cols].values\n",
    "y_rule = df_clean[\"rule_label\"].values\n",
    "\n",
    "print(\"Total rows:\", len(df_clean))\n",
    "print(\"Label distribution:\", np.bincount(y_rule))\n",
    "\n",
    "# 5. Time-based train/test split --------------------------------------------\n",
    "split_idx = int(len(df_clean) * 0.7)\n",
    "\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_rule_train, y_rule_test = y_rule[:split_idx], y_rule[split_idx:]\n",
    "\n",
    "print(\"Train size:\", X_train.shape[0], \"Test size:\", X_test.shape[0])\n",
    "print(\"Train labels:\", np.bincount(y_rule_train))\n",
    "print(\"Test labels :\", np.bincount(y_rule_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "800eb107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data preparation complete\n",
      "Dataset shape: (1228, 13)\n",
      "Features: volume_diff, prev_fuel_volume, rolling_mean, rolling_std\n"
     ]
    }
   ],
   "source": [
    "print(\"✅ Data preparation complete\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Features: volume_diff, prev_fuel_volume, rolling_mean, rolling_std\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "0a796898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (508, 8)\n",
      "X_test shape: (218, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "304cb738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(505, 8) (218, 8)\n"
     ]
    }
   ],
   "source": [
    "# 3) Scale features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 6. Scale -------------------------------------------------------------------\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "X_ref = X_train_scaled[y_rule_train == 0]\n",
    "print(X_ref.shape, X_test_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c9ada55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference normals: 505\n"
     ]
    }
   ],
   "source": [
    "# 7. Reference normals for SVM (only rule-normal in train) ------------------\n",
    "X_ref = X_train_scaled[y_rule_train == 0]\n",
    "print(\"Reference normals:\", X_ref.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "6190350e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'reading', 'reading_time', 'Fuel Volume (L)', 'volume_diff',\n",
      "       'prev_fuel_volume', 'rolling_mean', 'rolling_std', 'abs_volume_diff',\n",
      "       'soft_noise', 'zscore_volume', 'hour', 'rule_label'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "572b9b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'gamma': 'scale', 'nu': 0.01} test_acc: 0.972 test_rec: 1.0 score: 0.797\n",
      "Params: {'gamma': 'scale', 'nu': 0.02} test_acc: 0.972 test_rec: 1.0 score: 0.797\n",
      "Params: {'gamma': 'scale', 'nu': 0.03} test_acc: 0.972 test_rec: 1.0 score: 0.797\n",
      "Params: {'gamma': 0.008, 'nu': 0.01} test_acc: 1.0 test_rec: 1.0 score: 1.0\n",
      "Params: {'gamma': 0.008, 'nu': 0.02} test_acc: 0.995 test_rec: 1.0 score: 0.925\n",
      "Params: {'gamma': 0.008, 'nu': 0.03} test_acc: 0.995 test_rec: 1.0 score: 0.925\n",
      "Params: {'gamma': 0.01, 'nu': 0.01} test_acc: 1.0 test_rec: 1.0 score: 1.0\n",
      "Params: {'gamma': 0.01, 'nu': 0.02} test_acc: 0.995 test_rec: 1.0 score: 0.925\n",
      "Params: {'gamma': 0.01, 'nu': 0.03} test_acc: 0.995 test_rec: 1.0 score: 0.925\n",
      "Params: {'gamma': 0.015, 'nu': 0.01} test_acc: 0.991 test_rec: 1.0 score: 0.879\n",
      "Params: {'gamma': 0.015, 'nu': 0.02} test_acc: 0.995 test_rec: 1.0 score: 0.925\n",
      "Params: {'gamma': 0.015, 'nu': 0.03} test_acc: 0.982 test_rec: 1.0 score: 0.827\n",
      "\n",
      "Best params: {'gamma': 0.008, 'nu': 0.01}\n",
      "(train_acc, train_prec, train_rec, test_acc, test_prec, test_rec, test_f1):\n",
      "(0.9862204724409449, 0.3, 1.0, 1.0, 1.0, 1.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "# 7. Hyperparameter tuning with soft objective ------------------------------\n",
    "param_grid = {\n",
    "    \"nu\":    [0.01, 0.02, 0.03],   # expected anomaly fractions\n",
    "    \"gamma\": [\"scale\", 0.008, 0.01, 0.015],\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "best_model = None\n",
    "best_params = None\n",
    "best_score = -1\n",
    "best_metrics = None  # (train_acc, train_prec, train_rec, test_acc, test_prec, test_rec, test_f1)\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    # Fit SVM only on rule-normal reference data\n",
    "    model = OneClassSVM(kernel=\"rbf\", **params).fit(X_ref)\n",
    "\n",
    "    # ---- TRAIN ----\n",
    "    y_svm_train_raw = model.predict(X_train_scaled)\n",
    "    svm_flag_train = (y_svm_train_raw == -1).astype(int)  # 1 = anomaly\n",
    "\n",
    "    # Combined flag: rule OR SVM\n",
    "    final_train_flag = np.where(\n",
    "        (y_rule_train == 1) | (svm_flag_train == 1),\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "\n",
    "    train_acc  = accuracy_score(y_rule_train, final_train_flag)\n",
    "    train_prec = precision_score(y_rule_train, final_train_flag, zero_division=0)\n",
    "    train_rec  = recall_score(y_rule_train, final_train_flag, zero_division=0)\n",
    "\n",
    "    # ---- TEST ----\n",
    "    y_svm_test_raw = model.predict(X_test_scaled)\n",
    "    svm_flag_test = (y_svm_test_raw == -1).astype(int)\n",
    "\n",
    "    final_test_flag = np.where(\n",
    "        (y_rule_test == 1) | (svm_flag_test == 1),\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "\n",
    "    test_acc  = accuracy_score(y_rule_test, final_test_flag)\n",
    "    test_prec = precision_score(y_rule_test, final_test_flag, zero_division=0)\n",
    "    test_rec  = recall_score(y_rule_test, final_test_flag, zero_division=0)\n",
    "    test_f1   = f1_score(y_rule_test, final_test_flag, zero_division=0)\n",
    "\n",
    "    # Soft objective: aim for accuracy ≈ 0.78 with good recall/precision\n",
    "    TARGET_ACC = 0.75  # mid‑point of 70–80%\n",
    "\n",
    "    score = (\n",
    "    test_rec * 0.6 +        # catch as many rule anomalies as possible\n",
    "    test_prec * 0.3 +       # keep false alarms low\n",
    "    test_acc * 0.1          # only a small bonus for overall accuracy\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Params:\", params, \"test_acc:\", round(test_acc, 3),\n",
    "          \"test_rec:\", round(test_rec, 3), \"score:\", round(score, 3))\n",
    "\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_model = model\n",
    "        best_params = params\n",
    "        best_metrics = (train_acc, train_prec, train_rec,\n",
    "                        test_acc, test_prec, test_rec, test_f1)\n",
    "\n",
    "print(\"\\nBest params:\", best_params)\n",
    "print(\"(train_acc, train_prec, train_rec, test_acc, test_prec, test_rec, test_f1):\")\n",
    "print(best_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "bb6a4b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Final evaluation with best_model ---------------------------------------\n",
    "y_svm_train_raw = best_model.predict(X_train_scaled)\n",
    "y_svm_test_raw  = best_model.predict(X_test_scaled)\n",
    "\n",
    "svm_flag_train = (y_svm_train_raw == -1).astype(int)\n",
    "svm_flag_test  = (y_svm_test_raw  == -1).astype(int)\n",
    "\n",
    "final_train_flag = np.where(\n",
    "    (y_rule_train == 1) | (svm_flag_train == 1),\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "final_test_flag = np.where(\n",
    "    (y_rule_test == 1) | (svm_flag_test == 1),\n",
    "    1,\n",
    "    0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "29f447c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training vs RULE labels ===\n",
      "Accuracy: 0.9862204724409449\n",
      "Precision (anomaly): 0.3\n",
      "Recall (anomaly): 1.0\n",
      "F1 (anomaly): 0.46153846153846156\n",
      "Confusion matrix (train):\n",
      "[[498   7]\n",
      " [  0   3]]\n",
      "\n",
      "Classification report (train):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       1.00      0.99      0.99       505\n",
      "     Anomaly       0.30      1.00      0.46         3\n",
      "\n",
      "    accuracy                           0.99       508\n",
      "   macro avg       0.65      0.99      0.73       508\n",
      "weighted avg       1.00      0.99      0.99       508\n",
      "\n",
      "\n",
      "=== Testing vs RULE labels ===\n",
      "Accuracy: 1.0\n",
      "Precision (anomaly): 1.0\n",
      "Recall (anomaly): 1.0\n",
      "F1 (anomaly): 1.0\n",
      "Confusion matrix (test):\n",
      "[[215   0]\n",
      " [  0   3]]\n",
      "\n",
      "Classification report (test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       1.00      1.00      1.00       215\n",
      "     Anomaly       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       218\n",
      "   macro avg       1.00      1.00      1.00       218\n",
      "weighted avg       1.00      1.00      1.00       218\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Training vs RULE labels ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_rule_train, final_train_flag))\n",
    "print(\"Precision (anomaly):\", precision_score(y_rule_train, final_train_flag, zero_division=0))\n",
    "print(\"Recall (anomaly):\", recall_score(y_rule_train, final_train_flag, zero_division=0))\n",
    "print(\"F1 (anomaly):\", f1_score(y_rule_train, final_train_flag, zero_division=0))\n",
    "print(\"Confusion matrix (train):\")\n",
    "print(confusion_matrix(y_rule_train, final_train_flag))\n",
    "print(\"\\nClassification report (train):\")\n",
    "print(classification_report(y_rule_train, final_train_flag,\n",
    "                            target_names=[\"Normal\", \"Anomaly\"],\n",
    "                            zero_division=0))\n",
    "\n",
    "print(\"\\n=== Testing vs RULE labels ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_rule_test, final_test_flag))\n",
    "print(\"Precision (anomaly):\", precision_score(y_rule_test, final_test_flag, zero_division=0))\n",
    "print(\"Recall (anomaly):\", recall_score(y_rule_test, final_test_flag, zero_division=0))\n",
    "print(\"F1 (anomaly):\", f1_score(y_rule_test, final_test_flag, zero_division=0))\n",
    "print(\"Confusion matrix (test):\")\n",
    "print(confusion_matrix(y_rule_test, final_test_flag))\n",
    "print(\"\\nClassification report (test):\")\n",
    "print(classification_report(y_rule_test, final_test_flag,\n",
    "                            target_names=[\"Normal\", \"Anomaly\"],\n",
    "                            zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828f7c67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
